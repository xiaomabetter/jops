### Hadoop

==== 概况

Hadoop 集群用于日志归档和统计分析。

目前，环信的 Hadoop 集群部署在青云北京二区。

部署情况为：

* qc-bj2-hadoop[1-8]: Hadoop/HBase
* qc-bj2-kafka[1-3]: Kafka/OpenTSDB

==== 基本环境安装（模版）

[source,console]
----
# run as root
yum install http://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm -y
yum intall http://yum.puppetlabs.com/puppetlabs-release-el-7.noarch.rpm -y
yum install puppet -y
curl -s http://yum.op.easemob.com/yum/easemob.repo -o /etc/yum.repos.d/easemob.repo

puppet agent --confdir /etc/puppet --certname $(hostname) --server puppet.op.easemob.com --genconfig > /etc/puppet/puppet.conf

yum install java -y
echo 'JAVA_HOME=/usr/java/latest' > /etc/profile.d/java.sh

useradd easemob
echo 'easemob        ALL=(ALL)       NOPASSWD: ALL' > /etc/sudoers.d/easemob

# run as easemob
mkdir ~easemob/.ssh -p && chmod 400 ~easemob/.ssh
echo 'ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDFJOoUAnrnniV4PbxsPIC3qAwRxVedHX2064y3/MMIDxY3CvNa3opbg12xCOmNjMWrv4q8Vm/LPh743YVIQ+ip4fMIjviM/KxidRr+rBD+coOkLbotCw7SFLzpCXHex6ZrpbYoTPHp2hUvb6N1bGOcwcqxLfVtnw24lJ2lToXaOugDhTNhsTGr0ERJI3SSQR5wICl72oRY6gxlJTlG6RCn42UtNm5BldUb9mb8nrMo59WRKUV1bzzoRnogltNlFgp+PO4Sp/ZW9ll7mUb0ncDO0IKx8ssnHvDGhKfUMyQv8uysdRb8RQEI4Nc6/xUsiE+18XvswB2xo1eKLOdU+BoR easemob@qc-bj2-console' > ~easemob/.ssh/authorized_keys
----

==== Zookeeper
===== 概况

Zookeeper 用于 HBase / Kafka / OpenTSDB 集群状态同步。

===== 安装

[source,console]
----
# as easemob
sudo yum install easemob-zookeeper -y

sudo mkdir /data/apps/ -p && sudo chown easemob.easemob /data/apps/ -R

mkdir /data/apps/{opt,config,var,log,data} -p
----

qc-bj2-kafka1
[source,console]
----
echo 1 > /data/apps/data/zookeeper/myid
----

qc-bj2-kafka2
[source,console]
----
echo 2 > /data/apps/data/zookeeper/myid
----

qc-bj2-kafka3
[source,console]
----
echo 3 > /data/apps/data/zookeeper/myid
----

配置文件

./data/apps/config/zookeeper/zoo.cfg
----
tickTime=2000
initLimit=10
syncLimit=5
dataDir=/data/apps/data/zookeeper
clientPort=2181
autopurge.snapRetainCount=5
autopurge.purgeInterval=24
server.1=qc-bj2-kafka1:2888:3888
server.2=qc-bj2-kafka2:2888:3888
server.3=qc-bj2-kafka3:2888:3888
----

===== 基本操作命令
有两组 Zookeeper，分别用于 HBase 和 Kafka/OpenTSDB。

用于 Hbase: qc-bj2-hadoop[6,7,8]

启动
[source,console]
----
sudo su - zookeeper
cd /data/apps/opt/zookeeper/zookeeper-3.4.5/bin && ./zkServer.sh start
----

停止
[source,console]
----
sudo su - zookeeper
cd /data/apps/opt/zookeeper/zookeeper-3.4.5/bin && ./zkServer.sh stop
----

用于 Kafka/OpenTSDB: qc-bj2-kafka[1,2,3]

启动
[source,console]
----
/data/apps/opt/zookeeper/bin/zkServer.sh start
----

停止
[source,console]
----
/data/apps/opt/zookeeper/bin/zkServer.sh stop
----

==== Hadoop - HDFS / YARN
===== 版本
===== 安装
===== 基本操作命令
qc-bj2-hadoop[1]

启动
[source,console]
----
sudo su - hadoop
cd /data/apps/opt/hadoop/hadoop-2.5.1/sbin/ && ./start-dfs.sh
cd /data/apps/opt/hadoop/hadoop-2.5.1/sbin/ && ./start-yarn.sh
----

停止
[source,console]
----
sudo su - hadoop
cd /data/apps/opt/hadoop/hadoop-2.5.1/sbin/ && ./stop-dfs.sh
cd /data/apps/opt/hadoop/hadoop-2.5.1/sbin/ && ./stop-yarn.sh
----

qc-bj2-hadoop[3]

启动
[source,console]
----
sudo su - hadoop
cd /data/apps/opt/hadoop/hadoop-2.5.1/sbin/ && ./yarn-daemon.sh start resourcemanager && ./mr-jobhistory-daemon.sh start historyserver
----

停止
[source,console]
----
sudo su - hadoop
cd /data/apps/opt/hadoop/hadoop-2.5.1/sbin/ && ./yarn-daemon.sh stop resourcemanager && ./mr-jobhistory-daemon.sh stop historyserver
----

==== HBase
===== 版本
===== 安装
===== 基本操作命令
qc-bj2-hadoop[1]

启动
[source,console]
----
sudo su - hbase
cd /data/apps/opt/hbase/hbase-0.98.7-hadoop2/bin/ && ./start-hbase.sh
----

停止
[source,console]
----
sudo su - hbase
cd /data/apps/opt/hbase/hbase-0.98.7-hadoop2/bin/ && ./stop-hbase.sh
----

qc-bj2-hadoop[4,5]

启动
[source,console]
----
sudo su - hbase
cd /data/apps/opt/hbase/hbase-0.98.7-hadoop2/bin/ && ./hbase-daemon.sh start master
----

停止
[source,console]
----
sudo su - hbase
cd /data/apps/opt/hbase/hbase-0.98.7-hadoop2/bin/ && ./hbase-daemon.sh stop master
----

==== Kafka
===== 版本
===== 安装

[source,console]
----
sudo yum install easemob-kafka -y
----

配置文件。需要根据实际情况修改。

./data/apps/config/kafka/server.properties
----
broker.id=25     # CHANGE THIS
port=9092
host.name=192.168.100.25     # CHANGE THIS
num.network.threads=3
num.io.threads=8
socket.send.buffer.bytes=1048576
socket.receive.buffer.bytes=1048576
socket.request.max.bytes=104857600
log.dirs=/data/apps/log/kafka
num.partitions=2
num.recovery.threads.per.data.dir=1
log.retention.hours=168
log.segment.bytes=1073741824
log.retention.check.interval.ms=300000
log.cleaner.enable=false
zookeeper.connect=192.168.100.25:2181,192.168.100.26:2181,192.168.100.27:2181     # CHANGE THIS
zookeeper.connection.timeout.ms=60000
----

===== 基本操作命令
qc-bj2-kafka[1,2,3]

启动
[source,console]
----
/data/apps/opt/kafka/bin/kafka-server-start.sh /data/apps/config/kafka/server.properties >/dev/null 2>&1 &
----

==== OpenTSDB
===== 版本
===== 安装

[source,console]
----
sudo yum install opentsdb-plugins opentsdb -y

mkdir /data/apps/{data,log}/opentsdb
----

配置文件

./etc/opentsdb/opentsdb.conf
----
tsd.network.port = 4242
tsd.http.staticroot = /usr/share/opentsdb/static
tsd.http.cachedir = /data/apps/data/opentsdb
tsd.core.auto_create_metrics = true
tsd.core.meta.enable_tsuid_incrementing = true
tsd.storage.hbase.data_table = usergrid_metrics
tsd.storage.hbase.uid_table = usergrid-uid
tsd.storage.hbase.zk_quorum = 192.168.100.36:2181,192.168.100.37:2181,192.168.100.38:2181

tsd.core.plugin_path = /usr/share/opentsdb/plugins

em.kafka.tsdata.topic = tsdbtest
em.kafka.tsdata.topic.partiton = 1
em.kafka.zookeeper.connect = 192.168.100.25:2181,192.168.100.26:2181,192.168.100.27:2181
em.kafka.group.id = com.easemob.tsdb.kafka.plugin.KafkaConsumerGroups.a
tsd.rpc.plugins=com.easemob.tsdb.kafka.plugin.KafkaConsumerRPCPlugin
----

===== 基本操作命令
qc-bj2-kafka1

启动
[source,console]
----
sudo systemctl start opentsdb
----

停止
[source,console]
----
sudo systemctl start opentsdb
----

==== 日志与监控

==== 参数优化
